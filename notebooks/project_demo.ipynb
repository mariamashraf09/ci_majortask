{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAmU6itLcAQr",
        "outputId": "783eaf30-f1d2-4fb3-cd63-8a39613726c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analytical Gradient:\n",
            " [[-0.07902713  0.03102881 -0.03066677  0.01235341]\n",
            " [-0.02321936  0.02022031 -0.0303712   0.01507246]]\n",
            "Numerical Gradient:\n",
            " [[-0.07902713  0.03102881 -0.03066677  0.01235341]\n",
            " [-0.02321936  0.02022031 -0.0303712   0.01507246]]\n",
            "Relative Difference: 3.8799112938026197e-11\n",
            "Gradient check passed!\n"
          ]
        }
      ],
      "source": [
        "# Section 1: Gradient Checking\n",
        "import numpy as np\n",
        "from network import Network\n",
        "from layers import Dense\n",
        "from activations import Sigmoid, Tanh\n",
        "from losses import MSE\n",
        "\n",
        "# XOR dataset\n",
        "X = np.array([[0,0],\n",
        "              [0,1],\n",
        "              [1,0],\n",
        "              [1,1]])\n",
        "y = np.array([[0],\n",
        "              [1],\n",
        "              [1],\n",
        "              [0]])\n",
        "\n",
        "# Small network for XOR\n",
        "model = Network([\n",
        "    Dense(2, 4),\n",
        "    Tanh(),\n",
        "    Dense(4, 1),\n",
        "    Sigmoid()\n",
        "])\n",
        "\n",
        "loss_fn = MSE()\n",
        "epsilon = 1e-5\n",
        "\n",
        "# Forward pass\n",
        "pred = model.forward(X)\n",
        "loss = loss_fn.forward(y, pred)\n",
        "\n",
        "# Backward pass to compute analytical gradients\n",
        "grad_loss = loss_fn.backward(y, pred)\n",
        "model.backward(grad_loss)\n",
        "\n",
        "# Pick first layer weights for demonstration\n",
        "W = model.layers[0].W\n",
        "grad_analytic = model.layers[0].dW  # now this should not be None\n",
        "\n",
        "# Compute numerical gradient\n",
        "numerical_grad = np.zeros_like(W)\n",
        "for i in range(W.shape[0]):\n",
        "    for j in range(W.shape[1]):\n",
        "        W[i,j] += epsilon\n",
        "        loss_plus = loss_fn.forward(y, model.forward(X))\n",
        "        W[i,j] -= 2*epsilon\n",
        "        loss_minus = loss_fn.forward(y, model.forward(X))\n",
        "        W[i,j] += epsilon  # reset\n",
        "\n",
        "        numerical_grad[i,j] = (loss_plus - loss_minus) / (2*epsilon)\n",
        "\n",
        "# Compare with analytical gradient\n",
        "print(\"Analytical Gradient:\\n\", grad_analytic)\n",
        "print(\"Numerical Gradient:\\n\", numerical_grad)\n",
        "diff = np.linalg.norm(grad_analytic - numerical_grad) / (np.linalg.norm(grad_analytic) + np.linalg.norm(numerical_grad))\n",
        "print(\"Relative Difference:\", diff)\n",
        "if diff < 1e-7:\n",
        "    print(\"Gradient check passed!\")\n",
        "else:\n",
        "    print(\"Gradient check failed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Section 2: The XOR problem (training and results) using my libraries\n",
        "import numpy as np\n",
        "from network import Network\n",
        "from layers import Dense\n",
        "from activations import Sigmoid, Tanh\n",
        "from losses import MSE\n",
        "from optimizer import SGD\n",
        "\n",
        "\n",
        "\n",
        "# XOR dataset\n",
        "X = np.array([[0,0],\n",
        "              [0,1],\n",
        "              [1,0],\n",
        "              [1,1]])\n",
        "\n",
        "y = np.array([[0],\n",
        "              [1],\n",
        "              [1],\n",
        "              [0]])\n",
        "\n",
        "# Build network: 2 → 4 → 1\n",
        "#2 input neurons (x1,x2), 4 hidden neurons, 1 output neuron\n",
        "model = Network([\n",
        "    Dense(2, 4),\n",
        "    #tanh provide non linearity to the 4 hidden neurons\n",
        "    Tanh(),\n",
        "    #takes 4 inputs from the hidden layer and outputs 0 or 1\n",
        "    Dense(4, 1),\n",
        "    #sigmoid outputs values between 0 and 1\n",
        "    Sigmoid()\n",
        "])\n",
        "\n",
        "loss_fn = MSE()\n",
        "optimizer = SGD(lr=0.1)\n",
        "\n",
        "# Training loop, 5000 iterations\n",
        "for epoch in range(5000):\n",
        "    pred = model.forward(X) #y^\n",
        "    loss = loss_fn.forward(y, pred)\n",
        "    grad = loss_fn.backward(y, pred) #dL/dy^\n",
        "    model.backward(grad) #backpropagate through the network\n",
        "    model.update(optimizer)\n",
        "#print loss each 50 iterations\n",
        "    if epoch % 500 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss = {loss:.5f}\")\n",
        "\n",
        "# Final predictions\n",
        "print(\"\\nFinal Predictions:\")\n",
        "print(model.forward(X))"
      ],
      "metadata": {
        "id": "8hEgpPrrdHcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21120e77-b19d-4f66-e2ce-50c2e232c472"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss = 0.31052\n",
            "Epoch 500, Loss = 0.09946\n",
            "Epoch 1000, Loss = 0.02994\n",
            "Epoch 1500, Loss = 0.01284\n",
            "Epoch 2000, Loss = 0.00742\n",
            "Epoch 2500, Loss = 0.00503\n",
            "Epoch 3000, Loss = 0.00374\n",
            "Epoch 3500, Loss = 0.00295\n",
            "Epoch 4000, Loss = 0.00242\n",
            "Epoch 4500, Loss = 0.00205\n",
            "\n",
            "Final Predictions:\n",
            "[[0.02308154]\n",
            " [0.95173663]\n",
            " [0.95966229]\n",
            " [0.05075619]]\n"
          ]
        }
      ]
    }
  ]
}